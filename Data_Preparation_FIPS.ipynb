{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVdT8XsGW7gz"
      },
      "source": [
        "Data Preparation (FIXED)\n",
        "## Notebook 1: Load, Standardize, and Validate All Data Sources\n",
        "\n",
        "**CRITICAL FIXES APPLIED:**\n",
        "1.  Use TRI \"PARENT COMPANY D and B NR\" field (not TRIFD or MAILING_NAME)\n",
        "2.  Parse CRSP with pipe delimiter and correct column names\n",
        "3.  Proper FACILITY_STATE handling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDwPLEMRW7g1",
        "outputId": "c1f35ddb-2a6c-4342-e974-51149e1a677d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Libraries loaded successfully\n",
            "Analysis started: 2025-12-04 12:35:40\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Libraries loaded successfully\")\n",
        "print(f\"Analysis started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtR2iB4YW7g2"
      },
      "source": [
        "## 1. Define Paths and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVwhiG9AW7g3",
        "outputId": "7566ce94-24a0-46e1-f0f2-a57cc1880e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path Configuration:\n",
            "  TRI Data: True ✓\n",
            "  CRSP Data: True ✓\n",
            "  EDGAR Data: True ✓\n",
            "  SHELDUS Data: True ✓\n",
            "\n",
            "Analysis Window: 2009-2023 (15 years)\n"
          ]
        }
      ],
      "source": [
        "# Base path\n",
        "BASE_PATH = Path('/content/drive/MyDrive/Paper1_Dataset')\n",
        "\n",
        "# Data source paths\n",
        "TRI_PATH = BASE_PATH / 'EPA TRI'\n",
        "CRSP_PATH = BASE_PATH / 'crspdata'\n",
        "EDGAR_PATH = BASE_PATH / 'SEC EDGAR'\n",
        "SHELDUS_PATH = BASE_PATH / 'SHELDUS'\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_PATH = Path('/content/drive/MyDrive/Paper1_Dataset/processed')\n",
        "OUTPUT_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "# Analysis time window\n",
        "START_YEAR = 2009\n",
        "END_YEAR = 2023\n",
        "\n",
        "print(\"Path Configuration:\")\n",
        "print(f\"  TRI Data: {TRI_PATH.exists()} ✓\" if TRI_PATH.exists() else f\"  TRI Data: ✗ NOT FOUND\")\n",
        "print(f\"  CRSP Data: {CRSP_PATH.exists()} ✓\" if CRSP_PATH.exists() else f\"  CRSP Data: ✗ NOT FOUND\")\n",
        "print(f\"  EDGAR Data: {EDGAR_PATH.exists()} ✓\" if EDGAR_PATH.exists() else f\"  EDGAR Data: ✗ NOT FOUND\")\n",
        "print(f\"  SHELDUS Data: {SHELDUS_PATH.exists()} ✓\" if SHELDUS_PATH.exists() else f\"  SHELDUS Data: ✗ NOT FOUND\")\n",
        "print(f\"\\nAnalysis Window: {START_YEAR}-{END_YEAR} ({END_YEAR - START_YEAR + 1} years)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbUgWA_1W7g3"
      },
      "source": [
        "## 2. Load and Parse CRSP Data (FIXED)\n",
        "\n",
        "**FIX:** Parse with pipe delimiter and extract column 13 (COMNAM) for company names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "643pb6x2W7g3",
        "outputId": "a40647f3-2956-4cf3-ec4a-7bdfbe34285a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PARSING CRSP HEADER FILE (FIXED)\n",
            "================================================================================\n",
            "Reading: sfz_hdr.dat (4.51 MB)\n",
            "\n",
            "✓ Successfully loaded: 38,872 records\n",
            "  Columns: ['PERMNO', 'CUSIP8', 'CUSIP9', 'TICKER', 'PERMCO', 'COMPNO', 'ISSUNO', 'HEXCD', 'HSICCD', 'BEGDAT', 'ENDDAT', 'SICCD', 'COMNAM', 'TICKER_SYM', 'NAICS', 'PRIMEXCH', 'TRDSTAT', 'SECSTAT', 'PERMCO_LINKTYPE']\n",
            "\n",
            "Verifying COMNAM field:\n",
            "  Non-null: 38,872\n",
            "  Unique companies: 32,868\n",
            "  Average name length: 20.6 characters\n",
            "\n",
            "Sample company names:\n",
            "   1. OPTIMUM MANUFACTURING INC\n",
            "   2. GAS NATURAL INC\n",
            "   3. BANCTRUST FINANCIAL GROUP INC\n",
            "   4. GREAT COUNTRY BK ASONIA CT\n",
            "   5. CLOSE OUTS PLUS INC\n",
            "   6. WESTERN ENERGY RESOURCES INC\n",
            "   7. A C F INDUSTRIES INC\n",
            "   8. SHAREDATA INC\n",
            "   9. GARDENAMERICA CORP\n",
            "  10. IROQUOIS BANCORP INC\n",
            "  11. CABOT MEDICAL CORP\n",
            "  12. A T C GROUP SERVICES INC\n",
            "  13. D P A C TECHNOLOGIES CORP\n",
            "  14. ARIZONA APPETITOS STORES INC\n",
            "  15. A J INDUSTRIES INC\n",
            "  16. A & M FOOD SERVICES INC\n",
            "  17. SCOTT TECHNOLOGIES INC\n",
            "  18. CONCURRENT COMPUTER CORP\n",
            "  19. DELTA COMPUTEC INC\n",
            "  20. I F R SYSTEMS INC\n",
            "\n",
            "TICKER vs COMNAM comparison:\n",
            "TICKER                        COMNAM\n",
            "   NaN     OPTIMUM MANUFACTURING INC\n",
            "   NaN               GAS NATURAL INC\n",
            "   NaN BANCTRUST FINANCIAL GROUP INC\n",
            "   NaN    GREAT COUNTRY BK ASONIA CT\n",
            "   NaN           CLOSE OUTS PLUS INC\n",
            "   NaN  WESTERN ENERGY RESOURCES INC\n",
            "   NaN          A C F INDUSTRIES INC\n",
            "   NaN                 SHAREDATA INC\n",
            "   NaN            GARDENAMERICA CORP\n",
            "   NaN          IROQUOIS BANCORP INC\n"
          ]
        }
      ],
      "source": [
        "def parse_crsp_header():\n",
        "    \"\"\"\n",
        "    Parse CRSP header file correctly.\n",
        "\n",
        "    CRITICAL FIX: Use pipe delimiter and proper column names.\n",
        "    Column 13 (index 12) contains actual company names.\n",
        "\n",
        "    File format:\n",
        "    PERMNO|CUSIP8|CUSIP9|TICKER|PERMCO|COMPNO|ISSUNO|HEXCD|HSICCD|BEGDAT|ENDDAT|SICCD|COMNAM|...\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"PARSING CRSP HEADER FILE (FIXED)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    hdr_file = CRSP_PATH / 'sfz_hdr.dat'\n",
        "\n",
        "    if not hdr_file.exists():\n",
        "        print(f\"✗ ERROR: {hdr_file} not found!\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Reading: {hdr_file.name} ({hdr_file.stat().st_size / 1e6:.2f} MB)\")\n",
        "\n",
        "    # Define CRSP column names based on documentation\n",
        "    crsp_columns = [\n",
        "        'PERMNO',      # 0: Permanent company number\n",
        "        'CUSIP8',      # 1: CUSIP 8-digit\n",
        "        'CUSIP9',      # 2: CUSIP 9-digit\n",
        "        'TICKER',      # 3: Stock ticker (THIS was in 'Unnamed: 3'!)\n",
        "        'PERMCO',      # 4: Permanent company number\n",
        "        'COMPNO',      # 5: Company number\n",
        "        'ISSUNO',      # 6: Issue number\n",
        "        'HEXCD',       # 7: Exchange code\n",
        "        'HSICCD',      # 8: SIC code\n",
        "        'BEGDAT',      # 9: Begin date\n",
        "        'ENDDAT',      # 10: End date\n",
        "        'SICCD',       # 11: SIC code\n",
        "        'COMNAM',      # 12: COMPANY NAME (THIS IS WHAT WE NEED!)\n",
        "        'TICKER_SYM',  # 13: Ticker symbol\n",
        "        'NAICS',       # 14: NAICS code\n",
        "        'PRIMEXCH',    # 15: Primary exchange\n",
        "        'TRDSTAT',     # 16: Trading status\n",
        "        'SECSTAT',     # 17: Security status\n",
        "        'PERMCO_LINKTYPE'  # 18: Link type\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Read with PIPE delimiter\n",
        "        df = pd.read_csv(hdr_file,\n",
        "                        delimiter='|',\n",
        "                        encoding='latin-1',\n",
        "                        names=crsp_columns,\n",
        "                        low_memory=False)\n",
        "\n",
        "        print(f\"\\n✓ Successfully loaded: {len(df):,} records\")\n",
        "        print(f\"  Columns: {list(df.columns)}\")\n",
        "\n",
        "        # Verify COMNAM contains actual company names\n",
        "        print(f\"\\nVerifying COMNAM field:\")\n",
        "        print(f\"  Non-null: {df['COMNAM'].notna().sum():,}\")\n",
        "        print(f\"  Unique companies: {df['COMNAM'].nunique():,}\")\n",
        "        print(f\"  Average name length: {df['COMNAM'].str.len().mean():.1f} characters\")\n",
        "\n",
        "        print(f\"\\nSample company names:\")\n",
        "        samples = df['COMNAM'].dropna().head(20).tolist()\n",
        "        for i, name in enumerate(samples, 1):\n",
        "            print(f\"  {i:2d}. {name}\")\n",
        "\n",
        "        # Compare TICKER vs COMNAM\n",
        "        print(f\"\\nTICKER vs COMNAM comparison:\")\n",
        "        comparison = df[['TICKER', 'COMNAM']].head(10)\n",
        "        print(comparison.to_string(index=False))\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Error parsing CRSP header: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Execute\n",
        "crsp_header = parse_crsp_header()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9lSWphQW7g4"
      },
      "source": [
        "## 3. Load EPA TRI Data (FIXED)\n",
        "\n",
        "**FIX:** Extract correct parent company field: \"72. PARENT COMPANY D and B NR\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRVFbbc6W7g5",
        "outputId": "8a88f45d-b2a1-42c6-e838-4936907b2d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LOADING EPA TRI DATA WITH CORRECTED COLUMN MAPPING (2009-2023)\n",
            "================================================================================\n",
            "  ✓ 2009: 81,681 facilities loaded\n",
            "      Sample FACILITY_STATE: ['OH', 'OH', 'OH', 'OH', 'OH', 'AL', 'AL', 'PA', 'PA', 'MI']\n",
            "      Sample FACILITY_COUNTY: ['STARK', 'STARK', 'STARK', 'STARK', 'STARK', 'LAUDERDALE', 'LAUDERDALE', 'NORTHAMPTON', 'NORTHAMPTON', 'ALLEGAN']\n",
            "  ✓ 2010: 82,134 facilities loaded\n",
            "  ✗ Data not available for 2011\n",
            "  ✓ 2012: 82,846 facilities loaded\n",
            "  ✓ 2013: 83,357 facilities loaded\n",
            "  ✓ 2014: 83,590 facilities loaded\n",
            "  ✓ 2015: 82,869 facilities loaded\n",
            "  ✓ 2016: 81,608 facilities loaded\n",
            "  ✓ 2017: 81,754 facilities loaded\n",
            "  ✓ 2018: 81,756 facilities loaded\n",
            "  ✓ 2019: 80,820 facilities loaded\n",
            "  ✓ 2020: 78,631 facilities loaded\n",
            "  ✓ 2021: 78,212 facilities loaded\n",
            "  ✓ 2022: 80,002 facilities loaded\n",
            "  ✓ 2023: 78,589 facilities loaded\n",
            "\n",
            "✓ COMBINED TRI DATA:\n",
            "  Total records: 1,137,849\n",
            "  Years loaded: 14 (missing: 1)\n",
            "  Unique facilities: 29,176\n",
            "  With parent company: 808,030 (71.0%)\n",
            "\n",
            "  FACILITY_STATE verification:\n",
            "    Type: object\n",
            "    Sample: ['OH', 'OH', 'OH', 'OH', 'OH', 'AL', 'AL', 'PA', 'PA', 'MI', 'CA', 'CA', 'FL', 'TX', 'PA', 'PA', 'PA', 'PA', 'LA', 'LA']\n",
            "    Unique values: 56\n"
          ]
        }
      ],
      "source": [
        "def load_tri_year(year):\n",
        "    \"\"\"\n",
        "    Load TRI data with CORRECT column mapping.\n",
        "\n",
        "    CRITICAL FIX: TRI file columns are SHIFTED!\n",
        "    - Column \"13. FACILITY COUNTY\" actually contains STATE (OH, CA, TX)\n",
        "    - Column \"14. FACILITY STATE\" actually contains ZIP codes\n",
        "    - Need to remap everything\n",
        "    \"\"\"\n",
        "    year_folder = TRI_PATH / f'us_{year}'\n",
        "\n",
        "    if not year_folder.exists():\n",
        "        print(f\"  ✗ Data not available for {year}\")\n",
        "        return None\n",
        "\n",
        "    file_1a = year_folder / f'US_1a_{year}.txt'\n",
        "\n",
        "    if not file_1a.exists():\n",
        "        print(f\"  ✗ US_1a file not found for {year}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Read with tab delimiter\n",
        "        df = pd.read_csv(\n",
        "            file_1a,\n",
        "            delimiter='\\t',\n",
        "            encoding='latin-1',\n",
        "            on_bad_lines='skip',\n",
        "            engine='python'\n",
        "        )\n",
        "\n",
        "        # CORRECTED column mapping (TRI file is shifted!)\n",
        "        # The column NAMES in the file don't match the actual DATA\n",
        "        column_mapping = {\n",
        "            '9. TRIFD': 'TRIFD',\n",
        "            '2. REPORTING YEAR': 'REPORTING_YEAR',\n",
        "            '10. FACILITY NAME': 'FACILITY_STREET',      # Actually contains STREET\n",
        "            '11. FACILITY STREET': 'FACILITY_CITY',      # Actually contains CITY\n",
        "            '12. FACILITY CITY': 'FACILITY_COUNTY',      # Actually contains COUNTY\n",
        "            '13. FACILITY COUNTY': 'FACILITY_STATE',     # Actually contains STATE! ✓\n",
        "            '14. FACILITY STATE': 'FACILITY_ZIP',        # Actually contains ZIP\n",
        "            '15. FACILITY ZIP CODE': 'UNKNOWN_1',        # Unknown data\n",
        "            '72. PARENT COMPANY D and B NR': 'PARENT_COMPANY',\n",
        "            '73. STANDARDIZED PARENT COMPANY NAME': 'PARENT_COMPANY_STD',\n",
        "            '18. MAILING NAME': 'MAILING_NAME',\n",
        "            '19. MAILING STREET': 'MAILING_STREET',\n",
        "            '20. MAILING CITY': 'MAILING_CITY',\n",
        "            '21. MAILING STATE': 'MAILING_STATE',\n",
        "        }\n",
        "\n",
        "        # Find which columns exist and rename\n",
        "        rename_map = {}\n",
        "        for old_name, new_name in column_mapping.items():\n",
        "            if old_name in df.columns:\n",
        "                rename_map[old_name] = new_name\n",
        "\n",
        "        if not rename_map:\n",
        "            print(f\"  ✗ No expected columns found in {year}\")\n",
        "            return None\n",
        "\n",
        "        # Select and rename\n",
        "        df_subset = df[list(rename_map.keys())].copy()\n",
        "        df_subset = df_subset.rename(columns=rename_map)\n",
        "\n",
        "        # Create COMPANY_NAME field\n",
        "        df_subset['COMPANY_NAME'] = df_subset['PARENT_COMPANY'].fillna(df_subset.get('TRIFD', ''))\n",
        "        df_subset['DATA_YEAR'] = year\n",
        "\n",
        "        print(f\"  ✓ {year}: {len(df_subset):,} facilities loaded\")\n",
        "\n",
        "        # DEBUG: Show sample for first year\n",
        "        if year == START_YEAR:\n",
        "            print(f\"      Sample FACILITY_STATE: {df_subset['FACILITY_STATE'].dropna().head(10).tolist()}\")\n",
        "            print(f\"      Sample FACILITY_COUNTY: {df_subset['FACILITY_COUNTY'].dropna().head(10).tolist()}\")\n",
        "\n",
        "        return df_subset\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error loading {year}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_all_tri_data():\n",
        "    \"\"\"Load TRI data for all years 2009-2023\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"LOADING EPA TRI DATA WITH CORRECTED COLUMN MAPPING ({START_YEAR}-{END_YEAR})\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    all_years = []\n",
        "\n",
        "    for year in range(START_YEAR, END_YEAR + 1):\n",
        "        df_year = load_tri_year(year)\n",
        "        if df_year is not None:\n",
        "            all_years.append(df_year)\n",
        "\n",
        "    if not all_years:\n",
        "        print(\"\\n✗ No TRI data loaded successfully!\")\n",
        "        return None\n",
        "\n",
        "    # Combine all years\n",
        "    df_all = pd.concat(all_years, ignore_index=True)\n",
        "\n",
        "    print(f\"\\n✓ COMBINED TRI DATA:\")\n",
        "    print(f\"  Total records: {len(df_all):,}\")\n",
        "    print(f\"  Years loaded: {len(all_years)} (missing: {(END_YEAR - START_YEAR + 1) - len(all_years)})\")\n",
        "    print(f\"  Unique facilities: {df_all['TRIFD'].nunique():,}\")\n",
        "    print(f\"  With parent company: {df_all['PARENT_COMPANY'].notna().sum():,} ({df_all['PARENT_COMPANY'].notna().sum()/len(df_all)*100:.1f}%)\")\n",
        "\n",
        "    # Verify FACILITY_STATE now contains actual states\n",
        "    print(f\"\\n  FACILITY_STATE verification:\")\n",
        "    print(f\"    Type: {df_all['FACILITY_STATE'].dtype}\")\n",
        "    print(f\"    Sample: {df_all['FACILITY_STATE'].dropna().head(20).tolist()}\")\n",
        "    print(f\"    Unique values: {df_all['FACILITY_STATE'].nunique()}\")\n",
        "\n",
        "    return df_all\n",
        "\n",
        "# Execute\n",
        "tri_data = load_all_tri_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjSBNCgnW7g5",
        "outputId": "92382467-8cd5-4b49-a076-c1b240709e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample TRI Records (showing parent company):\n",
            "================================================================================\n",
            "                                                TRIFD                    PARENT_COMPANY                                          COMPANY_NAME FACILITY_STATE\n",
            "                             ALLIANCE CASTINGS CO LLC              OHIO CASTINGS CO LLC                                  OHIO CASTINGS CO LLC             OH\n",
            "                             ALLIANCE CASTINGS CO LLC              OHIO CASTINGS CO LLC                                  OHIO CASTINGS CO LLC             OH\n",
            "                             ALLIANCE CASTINGS CO LLC              OHIO CASTINGS CO LLC                                  OHIO CASTINGS CO LLC             OH\n",
            "                             ALLIANCE CASTINGS CO LLC              OHIO CASTINGS CO LLC                                  OHIO CASTINGS CO LLC             OH\n",
            "                             ALLIANCE CASTINGS CO LLC              OHIO CASTINGS CO LLC                                  OHIO CASTINGS CO LLC             OH\n",
            "                    SOUTHEASTERN EXTRUSION & TOOL INC SOUTHEASTERN EXTRUSION & TOOL INC                     SOUTHEASTERN EXTRUSION & TOOL INC             AL\n",
            "                    SOUTHEASTERN EXTRUSION & TOOL INC SOUTHEASTERN EXTRUSION & TOOL INC                     SOUTHEASTERN EXTRUSION & TOOL INC             AL\n",
            "                             POLYTEK DEVELOPMENT CORP          POLYTEK DEVELOPMENT CORP                              POLYTEK DEVELOPMENT CORP             PA\n",
            "                             POLYTEK DEVELOPMENT CORP          POLYTEK DEVELOPMENT CORP                              POLYTEK DEVELOPMENT CORP             PA\n",
            "                           ALLEGAN METAL FINISHING CO                               NaN                            ALLEGAN METAL FINISHING CO             MI\n",
            "                       BASF CORP (RIVERSIDE FACILITY)                         BASF CORP                                             BASF CORP             CA\n",
            "                       BASF CORP (RIVERSIDE FACILITY)                         BASF CORP                                             BASF CORP             CA\n",
            "                    TITAN FLORIDA-MELBOURNE RMC PLANT                 TITAN AMERICA LLC                                     TITAN AMERICA LLC             FL\n",
            "CMC STEEL FABRICATORS INC. DBA CMC CAPITOL CITY STEEL                               NaN CMC STEEL FABRICATORS INC. DBA CMC CAPITOL CITY STEEL             TX\n",
            "                 SURTECO N.A. INC. JEANNETTE PA PLANT                               NaN                  SURTECO N.A. INC. JEANNETTE PA PLANT             PA\n",
            "                 SURTECO N.A. INC. JEANNETTE PA PLANT                               NaN                  SURTECO N.A. INC. JEANNETTE PA PLANT             PA\n",
            "                 SURTECO N.A. INC. JEANNETTE PA PLANT                               NaN                  SURTECO N.A. INC. JEANNETTE PA PLANT             PA\n",
            "                 SURTECO N.A. INC. JEANNETTE PA PLANT                               NaN                  SURTECO N.A. INC. JEANNETTE PA PLANT             PA\n",
            " EXXON MOBIL CORP - BATON ROUGE RESIN FINISHING PLANT                  EXXON MOBIL CORP                                      EXXON MOBIL CORP             LA\n",
            " EXXON MOBIL CORP - BATON ROUGE RESIN FINISHING PLANT                  EXXON MOBIL CORP                                      EXXON MOBIL CORP             LA\n",
            "\n",
            "================================================================================\n",
            "Field Comparison:\n",
            "================================================================================\n",
            "                                                   TRIFD                    PARENT_COMPANY       MAILING_NAME\n",
            "                                ALLIANCE CASTINGS CO LLC              OHIO CASTINGS CO LLC 1001 E BROADWAY ST\n",
            "                       SOUTHEASTERN EXTRUSION & TOOL INC SOUTHEASTERN EXTRUSION & TOOL INC        PO BOX 2218\n",
            "                                POLYTEK DEVELOPMENT CORP          POLYTEK DEVELOPMENT CORP       55 HILTON ST\n",
            "                              ALLEGAN METAL FINISHING CO                               NaN         PO BOX 217\n",
            "                          BASF CORP (RIVERSIDE FACILITY)                         BASF CORP    138 E MEATS AVE\n",
            "                       TITAN FLORIDA-MELBOURNE RMC PLANT                 TITAN AMERICA LLC  800 FAIRWAY DRIVE\n",
            "   CMC STEEL FABRICATORS INC. DBA CMC CAPITOL CITY STEEL                               NaN        PO BOX 3195\n",
            "                    SURTECO N.A. INC. JEANNETTE PA PLANT                               NaN  1001 CHAMBERS AVE\n",
            "    EXXON MOBIL CORP - BATON ROUGE RESIN FINISHING PLANT                  EXXON MOBIL CORP   12480 SCENIC HWY\n",
            "                           IOWA CONTRACT FABRICATORS INC                      OSHKOSH CORP   12150ADDISON AVE\n",
            "                                               3G MERMET                               NaN     5970 N MAIN ST\n",
            "                      HF SINCLAIR EL DORADO REFINING LLC                  HF SINCLAIR CORP        PO BOX 1121\n",
            "HEIDELBERG MATERIALS SOUTHEAST AGG LLC - TWIN CITY PLANT       HEIDELBERG MATERIALS US INC         PO BOX 459\n",
            "                           TITAN FLORIDA-COCOA RMC PLANT                 TITAN AMERICA LLC  800 FAIRWAY DRIVE\n",
            "            ROCHESTER PUBLIC UTILITIES SILVER LAKE PLANT        ROCHESTER PUBLIC UTILITIES 4000 E RIVER RD NE\n"
          ]
        }
      ],
      "source": [
        "# Display sample to verify correct fields\n",
        "if tri_data is not None:\n",
        "    print(\"\\nSample TRI Records (showing parent company):\")\n",
        "    print(\"=\"*80)\n",
        "    sample_cols = ['TRIFD', 'PARENT_COMPANY', 'COMPANY_NAME', 'FACILITY_NAME', 'FACILITY_STATE']\n",
        "    available = [col for col in sample_cols if col in tri_data.columns]\n",
        "    print(tri_data[available].head(20).to_string(index=False))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Field Comparison:\")\n",
        "    print(\"=\"*80)\n",
        "    comparison = tri_data[['TRIFD', 'PARENT_COMPANY', 'MAILING_NAME']].drop_duplicates().head(15)\n",
        "    print(comparison.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXMpCMiHW7g6"
      },
      "source": [
        "## 4. Standardize Company Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCDG0KuzW7g6",
        "outputId": "fbe465a7-8c34-4048-faa4-021a7c4af82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Standardization Test:\n",
            "================================================================================\n",
            "TYSON FOODS INC                          → TYSON FOODS\n",
            "General Motors Corporation               → GENERAL MOTORS\n",
            "Apple Inc.                               → APPLE\n",
            "Johnson & Johnson                        → JOHNSON AND JOHNSON\n"
          ]
        }
      ],
      "source": [
        "def standardize_company_name(name):\n",
        "    \"\"\"\n",
        "    Standardize company name for matching.\n",
        "    \"\"\"\n",
        "    if pd.isna(name) or name == '':\n",
        "        return ''\n",
        "\n",
        "    # Convert to string and uppercase\n",
        "    name = str(name).upper().strip()\n",
        "\n",
        "    # Replace common separators\n",
        "    name = re.sub(r'[,\\-/]', ' ', name)\n",
        "\n",
        "    # Replace & with AND\n",
        "    name = re.sub(r'\\s+&\\s+', ' AND ', name)\n",
        "\n",
        "    # Remove legal suffixes\n",
        "    legal_suffixes = [\n",
        "        r'\\bINCORPORATED\\b', r'\\bINC\\.?\\b', r'\\bCORPORATION\\b', r'\\bCORP\\.?\\b',\n",
        "        r'\\bCOMPANY\\b', r'\\bCO\\.?\\b', r'\\bLIMITED\\b', r'\\bLTD\\.?\\b',\n",
        "        r'\\bLLC\\b', r'\\bL\\.?L\\.?C\\.?\\b', r'\\bLP\\b', r'\\bLLP\\b', r'\\bPLC\\b',\n",
        "    ]\n",
        "\n",
        "    for suffix in legal_suffixes:\n",
        "        name = re.sub(suffix, '', name)\n",
        "\n",
        "    # Remove punctuation\n",
        "    name = re.sub(r'[^A-Z0-9\\s]', '', name)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    name = re.sub(r'\\s+', ' ', name).strip()\n",
        "\n",
        "    return name\n",
        "\n",
        "# Test\n",
        "test_names = [\n",
        "    'TYSON FOODS INC',\n",
        "    'General Motors Corporation',\n",
        "    'Apple Inc.',\n",
        "    'Johnson & Johnson',\n",
        "]\n",
        "\n",
        "print(\"\\nStandardization Test:\")\n",
        "print(\"=\"*80)\n",
        "for name in test_names:\n",
        "    print(f\"{name:40s} → {standardize_company_name(name)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J2CGzpPW7g6",
        "outputId": "770e7c38-4afc-4fa3-c52c-d5307d94ffc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Standardizing TRI company names...\n",
            "✓ Complete\n",
            "  Unique standardized names: 15,834\n",
            "\n",
            "Sample standardizations:\n",
            "                                         COMPANY_NAME                                 COMPANY_NAME_STD\n",
            "                                 OHIO CASTINGS CO LLC                                    OHIO CASTINGS\n",
            "                    SOUTHEASTERN EXTRUSION & TOOL INC                  SOUTHEASTERN EXTRUSION AND TOOL\n",
            "                             POLYTEK DEVELOPMENT CORP                              POLYTEK DEVELOPMENT\n",
            "                           ALLEGAN METAL FINISHING CO                          ALLEGAN METAL FINISHING\n",
            "                                            BASF CORP                                             BASF\n",
            "                                    TITAN AMERICA LLC                                    TITAN AMERICA\n",
            "CMC STEEL FABRICATORS INC. DBA CMC CAPITOL CITY STEEL CMC STEEL FABRICATORS DBA CMC CAPITOL CITY STEEL\n",
            "                 SURTECO N.A. INC. JEANNETTE PA PLANT                    SURTECO NA JEANNETTE PA PLANT\n",
            "                                     EXXON MOBIL CORP                                      EXXON MOBIL\n",
            "                                         OSHKOSH CORP                                          OSHKOSH\n",
            "                                            3G MERMET                                        3G MERMET\n",
            "                                     HF SINCLAIR CORP                                      HF SINCLAIR\n",
            "                          HEIDELBERG MATERIALS US INC                          HEIDELBERG MATERIALS US\n",
            "                           ROCHESTER PUBLIC UTILITIES                       ROCHESTER PUBLIC UTILITIES\n",
            "                     AIR LIQUIDE ADVANCED SEPARATIONS                 AIR LIQUIDE ADVANCED SEPARATIONS\n",
            "                                           CUBIC CORP                                            CUBIC\n",
            "                                RIO TINTO AMERICA INC                                RIO TINTO AMERICA\n",
            "                                   SOLVAY HOLDING INC                                   SOLVAY HOLDING\n",
            "                            ARCHER DANIELS MIDLAND CO                           ARCHER DANIELS MIDLAND\n",
            "                                          PEPSICO INC                                          PEPSICO\n",
            "\n",
            "Standardizing CRSP company names...\n",
            "✓ Complete\n",
            "  Unique standardized names: 32,675\n",
            "\n",
            "Sample standardizations:\n",
            "                       COMNAM                 COMNAM_STD\n",
            "    OPTIMUM MANUFACTURING INC      OPTIMUM MANUFACTURING\n",
            "              GAS NATURAL INC                GAS NATURAL\n",
            "BANCTRUST FINANCIAL GROUP INC  BANCTRUST FINANCIAL GROUP\n",
            "   GREAT COUNTRY BK ASONIA CT GREAT COUNTRY BK ASONIA CT\n",
            "          CLOSE OUTS PLUS INC            CLOSE OUTS PLUS\n",
            " WESTERN ENERGY RESOURCES INC   WESTERN ENERGY RESOURCES\n",
            "         A C F INDUSTRIES INC           A C F INDUSTRIES\n",
            "                SHAREDATA INC                  SHAREDATA\n",
            "           GARDENAMERICA CORP              GARDENAMERICA\n",
            "         IROQUOIS BANCORP INC           IROQUOIS BANCORP\n",
            "           CABOT MEDICAL CORP              CABOT MEDICAL\n",
            "     A T C GROUP SERVICES INC       A T C GROUP SERVICES\n",
            "    D P A C TECHNOLOGIES CORP       D P A C TECHNOLOGIES\n",
            " ARIZONA APPETITOS STORES INC   ARIZONA APPETITOS STORES\n",
            "           A J INDUSTRIES INC             A J INDUSTRIES\n",
            "      A & M FOOD SERVICES INC      A AND M FOOD SERVICES\n",
            "       SCOTT TECHNOLOGIES INC         SCOTT TECHNOLOGIES\n",
            "     CONCURRENT COMPUTER CORP        CONCURRENT COMPUTER\n",
            "           DELTA COMPUTEC INC             DELTA COMPUTEC\n",
            "            I F R SYSTEMS INC              I F R SYSTEMS\n"
          ]
        }
      ],
      "source": [
        "# Apply standardization to TRI\n",
        "if tri_data is not None:\n",
        "    print(\"\\nStandardizing TRI company names...\")\n",
        "    tri_data['COMPANY_NAME_STD'] = tri_data['COMPANY_NAME'].apply(standardize_company_name)\n",
        "\n",
        "    print(f\"✓ Complete\")\n",
        "    print(f\"  Unique standardized names: {tri_data['COMPANY_NAME_STD'].nunique():,}\")\n",
        "\n",
        "    print(\"\\nSample standardizations:\")\n",
        "    sample = tri_data[['COMPANY_NAME', 'COMPANY_NAME_STD']].drop_duplicates().head(20)\n",
        "    print(sample.to_string(index=False))\n",
        "\n",
        "# Apply standardization to CRSP\n",
        "if crsp_header is not None:\n",
        "    print(\"\\nStandardizing CRSP company names...\")\n",
        "    crsp_header['COMNAM_STD'] = crsp_header['COMNAM'].apply(standardize_company_name)\n",
        "\n",
        "    print(f\"✓ Complete\")\n",
        "    print(f\"  Unique standardized names: {crsp_header['COMNAM_STD'].nunique():,}\")\n",
        "\n",
        "    print(\"\\nSample standardizations:\")\n",
        "    sample = crsp_header[['COMNAM', 'COMNAM_STD']].drop_duplicates().head(20)\n",
        "    print(sample.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKMZikoSW7g6"
      },
      "source": [
        "## 5. Fix FACILITY_STATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQx5SyBbW7g6",
        "outputId": "a879d2bb-9367-414c-d48d-73089e704b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 5: CREATING STATE_ABBR FROM FACILITY_STATE\n",
            "================================================================================\n",
            "\n",
            "FACILITY_STATE is already in text format (2-letter codes)\n",
            "  Sample: ['OH', 'OH', 'OH', 'OH', 'OH', 'AL', 'AL', 'PA', 'PA', 'MI']\n",
            "\n",
            "✓ STATE_ABBR created:\n",
            "  With STATE_ABBR: 1,141,457 (100.0%)\n",
            "\n",
            "  Top 10 states by facility count:\n",
            "STATE_ABBR\n",
            "TX    123317\n",
            "OH     73243\n",
            "IL     54780\n",
            "PA     53937\n",
            "CA     53307\n",
            "IN     48265\n",
            "MI     42769\n",
            "LA     41391\n",
            "WI     39793\n",
            "NC     32782\n",
            "Name: count, dtype: int64\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 5: CREATING STATE_ABBR FROM FACILITY_STATE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if tri_data is not None and 'FACILITY_STATE' in tri_data.columns:\n",
        "\n",
        "    print(f\"\\nFACILITY_STATE is already in text format (2-letter codes)\")\n",
        "    print(f\"  Sample: {tri_data['FACILITY_STATE'].dropna().head(10).tolist()}\")\n",
        "\n",
        "    # Simply clean and copy\n",
        "    tri_data['STATE_ABBR'] = tri_data['FACILITY_STATE'].str.upper().str.strip()\n",
        "\n",
        "    converted = tri_data['STATE_ABBR'].notna().sum()\n",
        "\n",
        "    print(f\"\\n✓ STATE_ABBR created:\")\n",
        "    print(f\"  With STATE_ABBR: {converted:,} ({converted/len(tri_data)*100:.1f}%)\")\n",
        "\n",
        "    if converted > 0:\n",
        "        print(f\"\\n  Top 10 states by facility count:\")\n",
        "        print(tri_data['STATE_ABBR'].value_counts().head(10))\n",
        "\n",
        "else:\n",
        "    print(\"\\n    Cannot convert: tri_data is None or FACILITY_STATE missing\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F12gxCMW7g7"
      },
      "source": [
        "## 5.5  CREATE FIPS COUNTY CODES\n",
        "\n",
        "**CRITICAL ADDITION:** This step creates FIPS county codes\n",
        "\n",
        "This fixes the downstream disaster linkage issue that was causing 0% exposure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbxt7NumW7g7",
        "outputId": "f5fb1773-c5c5-4f49-a9ce-90935b1dc012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 5.5: CREATING FIPS COUNTY CODES (NEW!)\n",
            "================================================================================\n",
            "\n",
            "5.5.1 Downloading Census county FIPS crosswalk...\n",
            "  ✓ Downloaded 3,235 counties from Census\n",
            "\n",
            "5.5.2 Standardizing county names with improved algorithm...\n",
            "  Standardizing TRI county names...\n",
            "  Standardizing Census county names...\n",
            "\n",
            "  Standardization examples:\n",
            "    ST. LOUIS            → SAINTLOUIS\n",
            "    SAINT LOUIS          → SAINTLOUIS\n",
            "    LA SALLE             → LASALLE\n",
            "    DE KALB              → DEKALB\n",
            "    MC LEAN              → MCLEAN\n",
            "    PRINCE GEORGES       → PRINCEGEORGES\n",
            "\n",
            "5.5.3 Merging TRI facilities with FIPS codes...\n",
            "  ✓ STATE_ABBR found: 1,141,457 records\n",
            "\n",
            "✓ FIPS MATCHING COMPLETE:\n",
            "  Rows before: 1,141,457\n",
            "  Rows after: 1,148,673\n",
            "  With FIPS: 1,136,098\n",
            "  Match rate: 98.9%\n",
            "\n",
            "  ✓ EXCELLENT: 98.9% match rate!\n",
            "\n",
            "  Sample matched facilities:\n",
            "STATE_ABBR         FACILITY_COUNTY  FIPS\n",
            "        OH                   STARK 39151\n",
            "        AL              LAUDERDALE 01077\n",
            "        PA             NORTHAMPTON 42095\n",
            "        MI                 ALLEGAN 26005\n",
            "        CA               RIVERSIDE 06065\n",
            "        FL                 BREVARD 12009\n",
            "        TX                    HAYS 48209\n",
            "        PA            WESTMORELAND 42129\n",
            "        LA EAST BATON ROUGE PARISH 22033\n",
            "        IA                  HOWARD 19089\n",
            "\n",
            "5.5.4 Saving county crosswalk for downstream notebooks...\n",
            "  ✓ Saved: /content/drive/MyDrive/Paper1_Dataset/processed/county_fips_crosswalk.csv\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 5.5: CREATING FIPS COUNTY CODES (NEW!)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if tri_data is not None:\n",
        "    print(\"\\n5.5.1 Downloading Census county FIPS crosswalk...\")\n",
        "\n",
        "    import urllib.request\n",
        "\n",
        "    url = \"https://www2.census.gov/geo/docs/reference/codes/files/national_county.txt\"\n",
        "\n",
        "    try:\n",
        "        county_data = pd.read_csv(\n",
        "            url,\n",
        "            encoding='latin-1',\n",
        "            names=['STATE_ABBR', 'STATE_FIPS', 'COUNTY_FIPS', 'COUNTY_NAME', 'CLASS']\n",
        "        )\n",
        "\n",
        "        # Create 5-digit FIPS code\n",
        "        county_data['FIPS'] = (\n",
        "            county_data['STATE_FIPS'].astype(str).str.zfill(2) +\n",
        "            county_data['COUNTY_FIPS'].astype(str).str.zfill(3)\n",
        "        )\n",
        "\n",
        "        print(f\"  ✓ Downloaded {len(county_data):,} counties from Census\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠️  Download failed: {e}\")\n",
        "        county_data = None\n",
        "\n",
        "    if county_data is not None:\n",
        "        print(\"\\n5.5.2 Standardizing county names with improved algorithm...\")\n",
        "\n",
        "        def standardize_county(name):\n",
        "            \"\"\"\n",
        "            Aggressive county name standardization for maximum match rate.\n",
        "\n",
        "            Handles common issues:\n",
        "            - ST. LOUIS → SAINTLOUIS\n",
        "            - LA SALLE → LASALLE\n",
        "            - DE KALB → DEKALB\n",
        "            - MC LEAN → MCLEAN\n",
        "            \"\"\"\n",
        "            if pd.isna(name) or name == '':\n",
        "                return ''\n",
        "\n",
        "            name = str(name).upper().strip()\n",
        "\n",
        "            # Fix common abbreviations\n",
        "            replacements = {\n",
        "                'ST.': 'SAINT', 'ST ': 'SAINT',\n",
        "                'STE.': 'SAINTE', 'STE ': 'SAINTE',\n",
        "                'MT.': 'MOUNT', 'MT ': 'MOUNT',\n",
        "                'FT.': 'FORT', 'FT ': 'FORT',\n",
        "            }\n",
        "            for old, new in replacements.items():\n",
        "                name = name.replace(old, new)\n",
        "\n",
        "            # Remove ALL spaces, periods, hyphens, apostrophes\n",
        "            for char in [' ', '.', '-', \"'\", ',']:\n",
        "                name = name.replace(char, '')\n",
        "\n",
        "            # Remove common suffixes\n",
        "            suffixes = ['COUNTY', 'PARISH', 'BOROUGH', 'CITY', 'MUNICIPIO', 'CNTY']\n",
        "            for suffix in suffixes:\n",
        "                if name.endswith(suffix):\n",
        "                    name = name[:-len(suffix)]\n",
        "\n",
        "            return name.strip()\n",
        "\n",
        "        # Apply to both datasets\n",
        "        print(\"  Standardizing TRI county names...\")\n",
        "        tri_data['FACILITY_COUNTY_STD'] = tri_data['FACILITY_COUNTY'].apply(standardize_county)\n",
        "\n",
        "        print(\"  Standardizing Census county names...\")\n",
        "        county_data['COUNTY_NAME_STD'] = county_data['COUNTY_NAME'].apply(standardize_county)\n",
        "\n",
        "        # Show examples\n",
        "        print(\"\\n  Standardization examples:\")\n",
        "        examples = [\n",
        "            'ST. LOUIS', 'SAINT LOUIS', 'LA SALLE', 'DE KALB',\n",
        "            'MC LEAN', 'PRINCE GEORGES'\n",
        "        ]\n",
        "        for ex in examples[:6]:\n",
        "            print(f\"    {ex:20s} → {standardize_county(ex)}\")\n",
        "\n",
        "        print(\"\\n5.5.3 Merging TRI facilities with FIPS codes...\")\n",
        "\n",
        "        # CRITICAL: Check if STATE_ABBR exists\n",
        "        if 'STATE_ABBR' not in tri_data.columns:\n",
        "            print(f\"  ⚠️  ERROR: STATE_ABBR column not found in tri_data!\")\n",
        "            print(f\"     Available columns: {list(tri_data.columns[:10])}...\")\n",
        "            print(f\"     FIPS matching cannot proceed.\")\n",
        "            print(f\"     Make sure Cell 13 (STATE conversion) ran successfully.\")\n",
        "        else:\n",
        "            print(f\"  ✓ STATE_ABBR found: {tri_data['STATE_ABBR'].notna().sum():,} records\")\n",
        "\n",
        "        # Count before merge\n",
        "        before_count = len(tri_data)\n",
        "\n",
        "        # Remove old FIPS if exists\n",
        "        if 'FIPS' in tri_data.columns:\n",
        "            tri_data = tri_data.drop(columns=['FIPS'])\n",
        "\n",
        "        # Merge on standardized names\n",
        "        tri_data = tri_data.merge(\n",
        "            county_data[['STATE_ABBR', 'COUNTY_NAME_STD', 'FIPS', 'COUNTY_NAME']],\n",
        "            left_on=['STATE_ABBR', 'FACILITY_COUNTY_STD'],\n",
        "            right_on=['STATE_ABBR', 'COUNTY_NAME_STD'],\n",
        "            how='left',\n",
        "            suffixes=('', '_census')\n",
        "        )\n",
        "\n",
        "        # Statistics\n",
        "        after_count = len(tri_data)\n",
        "        matched_count = tri_data['FIPS'].notna().sum()\n",
        "        match_rate = matched_count / after_count * 100\n",
        "\n",
        "        print(f\"\\n✓ FIPS MATCHING COMPLETE:\")\n",
        "        print(f\"  Rows before: {before_count:,}\")\n",
        "        print(f\"  Rows after: {after_count:,}\")\n",
        "        print(f\"  With FIPS: {matched_count:,}\")\n",
        "        print(f\"  Match rate: {match_rate:.1f}%\")\n",
        "\n",
        "        # Quality assessment\n",
        "        if match_rate >= 70:\n",
        "            print(f\"\\n  ✓ EXCELLENT: {match_rate:.1f}% match rate!\")\n",
        "        elif match_rate >= 50:\n",
        "            print(f\"\\n  ✓ GOOD: {match_rate:.1f}% match rate\")\n",
        "        else:\n",
        "            print(f\"\\n  ⚠️  LOW: {match_rate:.1f}% match rate\")\n",
        "            print(f\"  Investigating unmatched counties...\")\n",
        "\n",
        "            unmatched = tri_data[tri_data['FIPS'].isna()]\n",
        "            if len(unmatched) > 0:\n",
        "                top_unmatched = unmatched.groupby(\n",
        "                    ['STATE_ABBR', 'FACILITY_COUNTY']\n",
        "                ).size().sort_values(ascending=False).head(15)\n",
        "\n",
        "                print(f\"\\n  Top 15 unmatched counties:\")\n",
        "                print(f\"  {'State':<6} {'County':<35} {'Clean':<20} {'Count':<8}\")\n",
        "                print(f\"  {'-'*75}\")\n",
        "                for (state, county), count in top_unmatched.items():\n",
        "                    clean = standardize_county(county)\n",
        "                    print(f\"  {state:<6} {county:<35} {clean:<20} {count:>6,}\")\n",
        "\n",
        "        # Show matched samples\n",
        "        print(f\"\\n  Sample matched facilities:\")\n",
        "        matched_sample = tri_data[tri_data['FIPS'].notna()][['STATE_ABBR', 'FACILITY_COUNTY', 'FIPS']].drop_duplicates().head(10)\n",
        "        print(matched_sample.to_string(index=False))\n",
        "\n",
        "        # Save crosswalk for other notebooks\n",
        "        print(\"\\n5.5.4 Saving county crosswalk for downstream notebooks...\")\n",
        "        crosswalk_file = OUTPUT_PATH / 'county_fips_crosswalk.csv'\n",
        "        county_data[['STATE_ABBR', 'COUNTY_NAME', 'FIPS']].to_csv(crosswalk_file, index=False)\n",
        "        print(f\"  ✓ Saved: {crosswalk_file}\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\n⚠️  Could not create FIPS codes - crosswalk unavailable\")\n",
        "        tri_data['FIPS'] = None\n",
        "\n",
        "else:\n",
        "    print(\"\\n⚠️  tri_data is None - cannot create FIPS codes\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY0X1Y6tW7g7"
      },
      "source": [
        "## 6. Save Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASbzqgOOW7g7",
        "outputId": "97cd943c-9d64-4181-f2d9-dd90193c6524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SAVING PROCESSED DATA\n",
            "================================================================================\n",
            "✓ TRI saved: /content/drive/MyDrive/Paper1_Dataset/processed/tri_facilities_panel.parquet\n",
            "  Records: 1,148,673\n",
            "  Columns: ['TRIFD', 'REPORTING_YEAR', 'FACILITY_STREET', 'FACILITY_CITY', 'FACILITY_COUNTY', 'FACILITY_STATE', 'FACILITY_ZIP', 'UNKNOWN_1', 'PARENT_COMPANY', 'PARENT_COMPANY_STD', 'MAILING_NAME', 'MAILING_STREET', 'MAILING_CITY', 'MAILING_STATE', 'COMPANY_NAME', 'DATA_YEAR', 'COMPANY_NAME_STD', 'STATE_ABBR', 'FACILITY_COUNTY_STD', 'COUNTY_NAME_STD', 'COUNTY_NAME', 'COUNTY_NAME_STD_census', 'FIPS', 'COUNTY_NAME_census']\n",
            "\n",
            "✓ CRSP saved: /content/drive/MyDrive/Paper1_Dataset/processed/crsp_companies.parquet\n",
            "  Records: 38,872\n",
            "  Columns: ['PERMNO', 'CUSIP8', 'CUSIP9', 'TICKER', 'PERMCO', 'COMPNO', 'ISSUNO', 'HEXCD', 'HSICCD', 'BEGDAT']...\n",
            "\n",
            "================================================================================\n",
            "DATA PREPARATION COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "✅ Ready for Notebook 2: Automated Matching\n",
            "\n",
            "Expected improvements:\n",
            "  - Match rate should increase from 0.2% to 15-25%\n",
            "  - 5,000-8,000 high-quality matches expected\n",
            "  - Parent company coverage: ~62% of TRI facilities\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAVING PROCESSED DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save TRI\n",
        "if tri_data is not None:\n",
        "    output_file = OUTPUT_PATH / 'tri_facilities_panel.parquet'\n",
        "    tri_data.to_parquet(output_file, index=False)\n",
        "    print(f\"✓ TRI saved: {output_file}\")\n",
        "    print(f\"  Records: {len(tri_data):,}\")\n",
        "    print(f\"  Columns: {list(tri_data.columns)}\")\n",
        "\n",
        "# Save CRSP\n",
        "if crsp_header is not None:\n",
        "    output_file = OUTPUT_PATH / 'crsp_companies.parquet'\n",
        "    crsp_header.to_parquet(output_file, index=False)\n",
        "    print(f\"\\n✓ CRSP saved: {output_file}\")\n",
        "    print(f\"  Records: {len(crsp_header):,}\")\n",
        "    print(f\"  Columns: {list(crsp_header.columns)[:10]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA PREPARATION COMPLETE!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DIAGNOSTIC: Find the real STATE column in TRI data\n",
        "print(\"=\"*80)\n",
        "print(\"DIAGNOSTIC: FINDING ACTUAL STATE COLUMN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if tri_data is not None:\n",
        "    print(f\"\\nAll columns in tri_data:\")\n",
        "    for i, col in enumerate(tri_data.columns):\n",
        "        print(f\"  {i:2d}. {col}\")\n",
        "\n",
        "    print(f\"\\n\\nSample of ALL columns for first facility:\")\n",
        "    print(\"=\"*80)\n",
        "    sample = tri_data.head(1).T\n",
        "    sample.columns = ['Value']\n",
        "    print(sample.to_string())\n",
        "\n",
        "    print(f\"\\n\\nLooking for STATE-like data...\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Check each column for 2-letter state codes\n",
        "    for col in tri_data.columns:\n",
        "        if tri_data[col].dtype == 'object':  # Only check text columns\n",
        "            sample_vals = tri_data[col].dropna().head(100).unique()\n",
        "            # Check if values look like state codes (2 chars, all uppercase)\n",
        "            state_like = [str(v) for v in sample_vals if isinstance(v, str) and len(str(v).strip()) == 2 and str(v).strip().isupper()]\n",
        "            if len(state_like) > 3:\n",
        "                print(f\"\\n✓ Column '{col}' contains state-like values:\")\n",
        "                print(f\"  Sample: {state_like[:20]}\")\n",
        "                print(f\"  Unique: {len(state_like)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ycMBr4wdR3G",
        "outputId": "f592fee2-49dd-45f7-fbc6-aee7b4b3ec53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DIAGNOSTIC: FINDING ACTUAL STATE COLUMN\n",
            "================================================================================\n",
            "\n",
            "All columns in tri_data:\n",
            "   0. TRIFD\n",
            "   1. REPORTING_YEAR\n",
            "   2. FACILITY_STREET\n",
            "   3. FACILITY_CITY\n",
            "   4. FACILITY_COUNTY\n",
            "   5. FACILITY_STATE\n",
            "   6. FACILITY_ZIP\n",
            "   7. UNKNOWN_1\n",
            "   8. PARENT_COMPANY\n",
            "   9. PARENT_COMPANY_STD\n",
            "  10. MAILING_NAME\n",
            "  11. MAILING_STREET\n",
            "  12. MAILING_CITY\n",
            "  13. MAILING_STATE\n",
            "  14. COMPANY_NAME\n",
            "  15. DATA_YEAR\n",
            "  16. COMPANY_NAME_STD\n",
            "  17. STATE_ABBR\n",
            "  18. FACILITY_COUNTY_STD\n",
            "  19. COUNTY_NAME_STD\n",
            "  20. COUNTY_NAME\n",
            "  21. COUNTY_NAME_STD_census\n",
            "  22. FIPS\n",
            "  23. COUNTY_NAME_census\n",
            "\n",
            "\n",
            "Sample of ALL columns for first facility:\n",
            "================================================================================\n",
            "                                           Value\n",
            "TRIFD                   ALLIANCE CASTINGS CO LLC\n",
            "REPORTING_YEAR                                NO\n",
            "FACILITY_STREET               1001 E BROADWAY ST\n",
            "FACILITY_CITY                           ALLIANCE\n",
            "FACILITY_COUNTY                            STARK\n",
            "FACILITY_STATE                                OH\n",
            "FACILITY_ZIP                               44601\n",
            "UNKNOWN_1                                    NaN\n",
            "PARENT_COMPANY              OHIO CASTINGS CO LLC\n",
            "PARENT_COMPANY_STD                           NaN\n",
            "MAILING_NAME                  1001 E BROADWAY ST\n",
            "MAILING_STREET                          ALLIANCE\n",
            "MAILING_CITY                                  OH\n",
            "MAILING_STATE                                NaN\n",
            "COMPANY_NAME                OHIO CASTINGS CO LLC\n",
            "DATA_YEAR                                   2009\n",
            "COMPANY_NAME_STD                   OHIO CASTINGS\n",
            "STATE_ABBR                                    OH\n",
            "FACILITY_COUNTY_STD                        STARK\n",
            "COUNTY_NAME_STD                            STARK\n",
            "COUNTY_NAME                         Stark County\n",
            "COUNTY_NAME_STD_census                     STARK\n",
            "FIPS                                       39151\n",
            "COUNTY_NAME_census                  Stark County\n",
            "\n",
            "\n",
            "Looking for STATE-like data...\n",
            "================================================================================\n",
            "\n",
            "✓ Column 'FACILITY_STATE' contains state-like values:\n",
            "  Sample: ['OH', 'AL', 'PA', 'MI', 'CA', 'FL', 'TX', 'LA', 'IA', 'SC', 'KS', 'MN', 'DE', 'UT', 'MD', 'NY', 'WI', 'AZ', 'NJ', 'KY']\n",
            "  Unique: 27\n",
            "\n",
            "✓ Column 'MAILING_CITY' contains state-like values:\n",
            "  Sample: ['OH', 'AL', 'PA', 'MI', 'CA', 'FL', 'TX', 'LA', 'IA', 'SC', 'KS', 'GA', 'MN', 'DE', 'UT', 'IL', 'MD', 'NY', 'WI', 'AZ']\n",
            "  Unique: 29\n",
            "\n",
            "✓ Column 'STATE_ABBR' contains state-like values:\n",
            "  Sample: ['OH', 'AL', 'PA', 'MI', 'CA', 'FL', 'TX', 'LA', 'IA', 'SC', 'KS', 'MN', 'DE', 'UT', 'MD', 'NY', 'WI', 'AZ', 'NJ', 'KY']\n",
            "  Unique: 27\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}