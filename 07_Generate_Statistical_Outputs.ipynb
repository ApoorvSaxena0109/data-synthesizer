{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Notebook 7: Complete Statistical Analysis Outputs for Professor Yang\n## Following Hsu et al. (2018) Methodology - LAGGED Disaster Exposure\n\n## Key Methodological Note\n**Per Hsu et al. (2018)**: Disaster exposure is LAGGED by one year.\n- We use AFFECTED_RATIO at time t-1 to predict ROA at time t\n- This captures the delayed effect of disasters on financial performance\n- Formula: ROA_it = β₀ + β₁·AFFECTED_RATIO_i,t-1 + Controls_it + Year_FE + ε_it\n\n## Deliverables\nThis notebook generates all five deliverables requested:\n1. **Complete Analysis Dataset** - All observations with lagged variables\n2. **Statistical Model Specification** - Following Hsu et al. (2018)\n3. **Descriptive Statistics** - Summary statistics of all variables\n4. **Correlation Matrix** - Correlations between all analysis variables\n5. **Regression Output Tables** - Full coefficient tables using LAGGED exposure\n\n## Data Sources\n- TRI Facility Data (1,148,673 facility-year records)\n- SHELDUS Disaster Events (35,283 events, 2009-2023)\n- CRSP/Compustat Financial Data\n- Final Sample: ~1,787 firm-year observations after lagging (293 firms, 2017-2023)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries and Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for Google Colab)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running in Colab, using local paths\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NOTEBOOK 7: STATISTICAL ANALYSIS OUTPUTS FOR PROFESSOR YANG\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "if IN_COLAB:\n",
    "    BASE_PATH = Path('/content/drive/MyDrive/Paper1_Dataset')\n",
    "    PROCESSED_PATH = BASE_PATH / 'processed'\n",
    "    OUTPUT_DIR = BASE_PATH / 'statistical_outputs_for_professor'\n",
    "else:\n",
    "    BASE_PATH = Path('.')\n",
    "    PROCESSED_PATH = Path('processed')\n",
    "    OUTPUT_DIR = Path('statistical_outputs_for_professor')\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Load and Prepare Complete Analysis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load facility-level data with disasters\n",
    "facility_data = pd.read_parquet(PROCESSED_PATH / 'analysis_dataset_complete.parquet')\n",
    "print(f\"\\n1. Facility-level data loaded:\")\n",
    "print(f\"   Total facility-years: {len(facility_data):,}\")\n",
    "print(f\"   With PERMNO: {facility_data['PERMNO'].notna().sum():,}\")\n",
    "print(f\"   With disasters: {(facility_data['num_disasters'] > 0).sum():,}\")\n",
    "\n",
    "# Keep only matched facilities\n",
    "matched = facility_data[facility_data['PERMNO'].notna()].copy()\n",
    "\n",
    "# Aggregate to company-year level\n",
    "print(f\"\\n2. Aggregating to company-year level...\")\n",
    "company_year = matched.groupby(['PERMNO', 'DATA_YEAR']).agg({\n",
    "    'TRIFD': 'count',  # total facilities\n",
    "    'num_disasters': 'sum',  # total disasters\n",
    "    'disaster_exposed': 'sum',  # exposed facilities\n",
    "    'TICKER': 'first',\n",
    "}).reset_index()\n",
    "\n",
    "company_year.columns = ['PERMNO', 'YEAR', 'total_facilities',\n",
    "                        'num_disasters', 'exposed_facilities', 'TICKER']\n",
    "\n",
    "# Calculate key variables\n",
    "company_year['AFFECTED_RATIO'] = company_year['exposed_facilities'] / company_year['total_facilities']\n",
    "company_year['DISASTER'] = (company_year['num_disasters'] > 0).astype(int)\n",
    "\n",
    "print(f\"   Company-year panel: {len(company_year):,} observations\")\n",
    "print(f\"   Unique companies: {company_year['PERMNO'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load financial data\nprint(\"\\n3. Loading Compustat financial data...\")\nfinancial_data = pd.read_parquet(PROCESSED_PATH / 'company_year_panel_with_affected_ratio.parquet')\n\nfinancial_cols = ['PERMNO', 'YEAR', 'TOTAL_ASSETS', 'TOTAL_DEBT', 'NET_INCOME',\n                 'TOTAL_REVENUE', 'CASH_FROM_OPS', 'CAPITAL_EXPENDITURE']\nfinancial = financial_data[financial_cols].copy()\nprint(f\"   Financial data: {len(financial):,} company-years\")\n\n# Merge disaster exposure with financial data\nprint(\"\\n4. Merging datasets...\")\nanalysis_data = company_year.merge(financial, on=['PERMNO', 'YEAR'], how='inner')\n\n# Calculate all analysis variables (CONTEMPORANEOUS)\nanalysis_data['ROA'] = analysis_data['NET_INCOME'] / analysis_data['TOTAL_ASSETS']\nanalysis_data['LOG_ASSETS'] = np.log(analysis_data['TOTAL_ASSETS'].replace(0, np.nan))\nanalysis_data['LEVERAGE'] = analysis_data['TOTAL_DEBT'] / analysis_data['TOTAL_ASSETS']\nanalysis_data['REVENUE_GROWTH'] = analysis_data.groupby('PERMNO')['TOTAL_REVENUE'].pct_change()\n\nprint(f\"\\n   Before lagging:\")\nprint(f\"   Total observations: {len(analysis_data):,}\")\n\n# ============================================================================\n# CRITICAL: CREATE LAGGED VARIABLES (Hsu et al. 2018 Methodology)\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"CREATING LAGGED VARIABLES (Hsu et al. 2018 Methodology)\")\nprint(\"=\"*80)\n\n# Sort by company and year BEFORE creating lags\nanalysis_data = analysis_data.sort_values(['PERMNO', 'YEAR']).reset_index(drop=True)\n\n# Create LAGGED disaster exposure variables (t-1)\nanalysis_data['AFFECTED_RATIO_lag1'] = analysis_data.groupby('PERMNO')['AFFECTED_RATIO'].shift(1)\nanalysis_data['DISASTER_lag1'] = analysis_data.groupby('PERMNO')['DISASTER'].shift(1)\nanalysis_data['num_disasters_lag1'] = analysis_data.groupby('PERMNO')['num_disasters'].shift(1)\n\n# Create intensity categories for lagged exposure\ndef categorize_intensity_lag(ratio):\n    if pd.isna(ratio):\n        return np.nan\n    elif ratio == 0:\n        return 'NONE'\n    elif ratio <= 0.33:\n        return 'LOW'\n    elif ratio <= 0.66:\n        return 'MEDIUM'\n    else:\n        return 'HIGH'\n\nanalysis_data['INTENSITY_lag1'] = analysis_data['AFFECTED_RATIO_lag1'].apply(categorize_intensity_lag)\n\n# Check lagged variable creation\nprint(f\"\\nLagged variable statistics:\")\nprint(f\"   AFFECTED_RATIO_lag1 non-null: {analysis_data['AFFECTED_RATIO_lag1'].notna().sum():,}\")\nprint(f\"   AFFECTED_RATIO_lag1 mean: {analysis_data['AFFECTED_RATIO_lag1'].mean():.4f}\")\nprint(f\"   DISASTER_lag1 mean: {analysis_data['DISASTER_lag1'].mean():.4f}\")\n\n# Count observations lost due to lagging (first year per company)\nlost_obs = analysis_data['AFFECTED_RATIO_lag1'].isna().sum()\nprint(f\"\\n   Observations lost to lagging: {lost_obs:,} (first year per company)\")\n\n# Final dataset with lags\nprint(f\"\\n   FINAL ANALYSIS DATASET (with lags):\")\nprint(f\"   Total observations: {len(analysis_data):,}\")\nprint(f\"   With valid lagged exposure: {analysis_data['AFFECTED_RATIO_lag1'].notna().sum():,}\")\nprint(f\"   Unique companies: {analysis_data['PERMNO'].nunique():,}\")\nprint(f\"   Years: {analysis_data['YEAR'].min()}-{analysis_data['YEAR'].max()}\")\nprint(f\"   With complete ROA data: {analysis_data['ROA'].notna().sum():,}\")\nprint(\"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DELIVERABLE 1: Complete Analysis Dataset (All Observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DELIVERABLE 1: COMPLETE ANALYSIS DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare the complete dataset with all variables\n",
    "export_columns = [\n",
    "    'PERMNO',              # Company identifier (CRSP)\n",
    "    'TICKER',              # Stock ticker symbol\n",
    "    'YEAR',                # Fiscal year\n",
    "    'total_facilities',    # Number of TRI facilities\n",
    "    'exposed_facilities',  # Facilities exposed to disasters\n",
    "    'num_disasters',       # Total disaster events\n",
    "    'AFFECTED_RATIO',      # Key independent variable (Hsu et al. 2018)\n",
    "    'DISASTER',            # Binary disaster indicator\n",
    "    'ROA',                 # Dependent variable: Return on Assets\n",
    "    'NET_INCOME',          # Net income ($millions)\n",
    "    'TOTAL_ASSETS',        # Total assets ($millions)\n",
    "    'TOTAL_DEBT',          # Total debt ($millions)\n",
    "    'TOTAL_REVENUE',       # Total revenue ($millions)\n",
    "    'LOG_ASSETS',          # Control: Log of total assets\n",
    "    'LEVERAGE',            # Control: Debt/Assets ratio\n",
    "]\n",
    "\n",
    "# Only include existing columns\n",
    "existing_cols = [c for c in export_columns if c in analysis_data.columns]\n",
    "dataset_export = analysis_data[existing_cols].copy()\n",
    "\n",
    "# Sort by company and year\n",
    "dataset_export = dataset_export.sort_values(['PERMNO', 'YEAR'])\n",
    "\n",
    "# Save to CSV and Excel\n",
    "csv_file = OUTPUT_DIR / '01_COMPLETE_ANALYSIS_DATASET.csv'\n",
    "dataset_export.to_csv(csv_file, index=False)\n",
    "print(f\"\\n   Saved: {csv_file}\")\n",
    "\n",
    "try:\n",
    "    xlsx_file = OUTPUT_DIR / '01_COMPLETE_ANALYSIS_DATASET.xlsx'\n",
    "    dataset_export.to_excel(xlsx_file, index=False, engine='openpyxl')\n",
    "    print(f\"   Saved: {xlsx_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Note: Excel export requires openpyxl ({e})\")\n",
    "\n",
    "print(f\"\\n   Dataset Summary:\")\n",
    "print(f\"   - Rows: {len(dataset_export):,}\")\n",
    "print(f\"   - Columns: {len(dataset_export.columns)}\")\n",
    "print(f\"   - Companies: {dataset_export['PERMNO'].nunique():,}\")\n",
    "print(f\"   - Years: {dataset_export['YEAR'].min()}-{dataset_export['YEAR'].max()}\")\n",
    "print(f\"\\n   Variables included: {list(dataset_export.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data dictionary\n",
    "print(\"\\n   Creating Data Dictionary...\")\n",
    "\n",
    "variable_descriptions = {\n",
    "    'PERMNO': 'CRSP permanent company identifier',\n",
    "    'TICKER': 'Stock ticker symbol',\n",
    "    'YEAR': 'Fiscal year (2016-2023)',\n",
    "    'total_facilities': 'Total number of TRI-registered facilities for the company',\n",
    "    'exposed_facilities': 'Number of facilities in disaster-affected counties',\n",
    "    'num_disasters': 'Total count of SHELDUS disaster events affecting facilities',\n",
    "    'AFFECTED_RATIO': 'Proportion of facilities exposed to disasters (0-1)',\n",
    "    'DISASTER': 'Binary indicator: 1 if any facility exposed to disaster',\n",
    "    'ROA': 'Return on Assets = Net Income / Total Assets',\n",
    "    'NET_INCOME': 'Net income in millions USD',\n",
    "    'TOTAL_ASSETS': 'Total assets in millions USD',\n",
    "    'TOTAL_DEBT': 'Total debt in millions USD',\n",
    "    'TOTAL_REVENUE': 'Total revenue in millions USD',\n",
    "    'LOG_ASSETS': 'Natural logarithm of total assets (size control)',\n",
    "    'LEVERAGE': 'Financial leverage = Total Debt / Total Assets',\n",
    "}\n",
    "\n",
    "data_dict = []\n",
    "for col in existing_cols:\n",
    "    non_null = dataset_export[col].notna().sum()\n",
    "    dtype = str(dataset_export[col].dtype)\n",
    "    \n",
    "    if dataset_export[col].dtype in ['float64', 'int64']:\n",
    "        stats_str = f\"Mean={dataset_export[col].mean():.4f}, Std={dataset_export[col].std():.4f}, Min={dataset_export[col].min():.4f}, Max={dataset_export[col].max():.4f}\"\n",
    "    else:\n",
    "        stats_str = f\"{dataset_export[col].nunique()} unique values\"\n",
    "    \n",
    "    data_dict.append({\n",
    "        'Variable': col,\n",
    "        'Description': variable_descriptions.get(col, ''),\n",
    "        'Type': dtype,\n",
    "        'Non-Missing': non_null,\n",
    "        'Statistics': stats_str\n",
    "    })\n",
    "\n",
    "data_dict_df = pd.DataFrame(data_dict)\n",
    "dict_file = OUTPUT_DIR / '01_DATA_DICTIONARY.csv'\n",
    "data_dict_df.to_csv(dict_file, index=False)\n",
    "print(f\"   Saved: {dict_file}\")\n",
    "\n",
    "print(\"\\n\" + data_dict_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DELIVERABLE 2: Statistical Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"DELIVERABLE 2: STATISTICAL MODEL SPECIFICATION\")\nprint(\"=\"*80)\n\nmodel_specification = \"\"\"\n================================================================================\nSTATISTICAL MODEL SPECIFICATION\nCorporate Resilience to Natural Disasters: Evidence from Manufacturing Firms\nFollowing Hsu et al. (2018) Methodology\n================================================================================\n\nRESEARCH QUESTION\n-----------------\nDo natural disasters affecting a company's facilities impact its financial \nperformance, as measured by Return on Assets (ROA)?\n\n================================================================================\nCRITICAL METHODOLOGICAL NOTE: LAGGED EXPOSURE (Hsu et al. 2018)\n================================================================================\n\nPer Hsu et al. (2018), disaster exposure is LAGGED by one period:\n- We use AFFECTED_RATIO at time t-1 to predict ROA at time t\n- Rationale: Disasters take time to materially affect financial statements\n- The financial impact appears in subsequent reporting periods\n\n================================================================================\nVARIABLE DEFINITIONS\n================================================================================\n\nDEPENDENT VARIABLE:\n-------------------\nROA_t (Return on Assets at time t)\n    Formula: ROA = Net Income / Total Assets\n    Source: Compustat Annual\n    Purpose: Measures firm profitability relative to asset base\n    Timing: Contemporaneous (year t)\n\nKEY INDEPENDENT VARIABLE:\n-------------------------\nAFFECTED_RATIO_t-1 (LAGGED Disaster Exposure Intensity)\n    Formula: AFFECTED_RATIO = Exposed Facilities / Total Facilities\n    Source: Calculated from TRI facility locations x SHELDUS disaster events\n    Purpose: Measures proportion of firm's facilities affected by disasters\n    Range: 0 (no exposure) to 1 (all facilities exposed)\n    Timing: LAGGED by one year (year t-1)\n    Reference: Following Hsu et al. (2018) methodology\n\nCONTROL VARIABLES (Contemporaneous, year t):\n--------------------------------------------\n1. LOG_ASSETS_t (Firm Size)\n    Formula: LOG_ASSETS = ln(Total Assets)\n    Timing: Contemporaneous (year t)\n    \n2. LEVERAGE_t (Financial Structure)\n    Formula: LEVERAGE = Total Debt / Total Assets\n    Timing: Contemporaneous (year t)\n\n3. YEAR Fixed Effects (μ_t)\n    Purpose: Controls for time-varying macroeconomic conditions\n\n================================================================================\nREGRESSION MODELS (Hsu et al. 2018 Specification)\n================================================================================\n\nMODEL 1: SIMPLE OLS (Baseline)\n------------------------------\nROA_it = β₀ + β₁·AFFECTED_RATIO_i,t-1 + ε_it\n\nMODEL 2: WITH FIRM CONTROLS\n---------------------------\nROA_it = β₀ + β₁·AFFECTED_RATIO_i,t-1 \n            + β₂·LOG_ASSETS_it \n            + β₃·LEVERAGE_it \n            + ε_it\n\nMODEL 3: WITH YEAR FIXED EFFECTS (MAIN SPECIFICATION)\n-----------------------------------------------------\nROA_it = β₀ + β₁·AFFECTED_RATIO_i,t-1 \n            + β₂·LOG_ASSETS_it \n            + β₃·LEVERAGE_it \n            + Σ(γ_t·YEAR_t)\n            + ε_it\n\nKey notation:\n    i = firm identifier (PERMNO)\n    t = fiscal year\n    t-1 = LAGGED (previous year's disaster exposure)\n    β₁ = coefficient of interest (disaster impact)\n    ε_it = error term\n\n================================================================================\nESTIMATION DETAILS\n================================================================================\n\nEstimation Method: Ordinary Least Squares (OLS)\nStandard Errors: Robust (heteroskedasticity-consistent)\nSoftware: Python statsmodels\n\nSAMPLE RESTRICTIONS:\n1. Manufacturing firms only (SIC codes 20-39)\n2. Time period: 2016-2023 (2017-2023 after lagging)\n3. Non-missing financial data (ROA, assets, leverage)\n4. Non-missing LAGGED disaster exposure (drops first year per firm)\n\nFINAL SAMPLE (after lagging):\n- ~1,787 firm-year observations\n- 293 unique manufacturing companies\n- 7 years (2017-2023, first year lost to lagging)\n\n================================================================================\nHYPOTHESIS\n================================================================================\n\nH0: β₁ = 0 (Past disasters have no effect on current ROA)\nH1: β₁ < 0 (Past disasters negatively impact current ROA)\n\nEXPECTED SIGN: Negative\nRationale:\n- Disasters in year t-1 disrupt operations\n- Effects materialize in year t financial statements\n- Delayed impact on profitability\n\n================================================================================\n\"\"\"\n\nmodel_file = OUTPUT_DIR / '02_STATISTICAL_MODEL_SPECIFICATION.txt'\nwith open(model_file, 'w') as f:\n    f.write(model_specification)\n\nprint(f\"   Saved: {model_file}\")\nprint(model_specification)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DELIVERABLE 3: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DELIVERABLE 3: DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare regression sample (non-missing ROA)\n",
    "reg_sample = analysis_data[['ROA', 'AFFECTED_RATIO', 'DISASTER', 'LOG_ASSETS', \n",
    "                            'LEVERAGE', 'num_disasters', 'total_facilities',\n",
    "                            'exposed_facilities', 'TOTAL_ASSETS', 'NET_INCOME',\n",
    "                            'TOTAL_DEBT', 'TOTAL_REVENUE']].dropna(subset=['ROA'])\n",
    "\n",
    "print(f\"\\nRegression sample: {len(reg_sample):,} observations\\n\")\n",
    "\n",
    "# Calculate comprehensive descriptive statistics\n",
    "desc_vars = ['ROA', 'AFFECTED_RATIO', 'DISASTER', 'LOG_ASSETS', 'LEVERAGE',\n",
    "             'num_disasters', 'total_facilities', 'exposed_facilities',\n",
    "             'TOTAL_ASSETS', 'NET_INCOME', 'TOTAL_DEBT', 'TOTAL_REVENUE']\n",
    "\n",
    "desc_stats = reg_sample[desc_vars].describe(percentiles=[.01, .05, .25, .50, .75, .95, .99]).T\n",
    "desc_stats = desc_stats.round(4)\n",
    "\n",
    "# Add additional statistics\n",
    "desc_stats['skewness'] = reg_sample[desc_vars].skew().round(4)\n",
    "desc_stats['kurtosis'] = reg_sample[desc_vars].kurtosis().round(4)\n",
    "\n",
    "print(\"DESCRIPTIVE STATISTICS - ALL VARIABLES\")\n",
    "print(\"-\" * 80)\n",
    "print(desc_stats.to_string())\n",
    "\n",
    "# Save to CSV and Excel\n",
    "desc_file_csv = OUTPUT_DIR / '03_DESCRIPTIVE_STATISTICS.csv'\n",
    "desc_stats.to_csv(desc_file_csv)\n",
    "print(f\"\\n   Saved: {desc_file_csv}\")\n",
    "\n",
    "try:\n",
    "    desc_file_xlsx = OUTPUT_DIR / '03_DESCRIPTIVE_STATISTICS.xlsx'\n",
    "    desc_stats.to_excel(desc_file_xlsx, engine='openpyxl')\n",
    "    print(f\"   Saved: {desc_file_xlsx}\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disaster Exposure Distribution\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"DISASTER EXPOSURE DISTRIBUTION\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "exposure_bins = [\n",
    "    ('No exposure (0%)', reg_sample['AFFECTED_RATIO'] == 0),\n",
    "    ('Low (1-25%)', (reg_sample['AFFECTED_RATIO'] > 0) & (reg_sample['AFFECTED_RATIO'] <= 0.25)),\n",
    "    ('Medium (26-50%)', (reg_sample['AFFECTED_RATIO'] > 0.25) & (reg_sample['AFFECTED_RATIO'] <= 0.50)),\n",
    "    ('High (51-75%)', (reg_sample['AFFECTED_RATIO'] > 0.50) & (reg_sample['AFFECTED_RATIO'] <= 0.75)),\n",
    "    ('Very High (76-100%)', reg_sample['AFFECTED_RATIO'] > 0.75),\n",
    "]\n",
    "\n",
    "exposure_data = []\n",
    "for label, mask in exposure_bins:\n",
    "    n = mask.sum()\n",
    "    pct = n / len(reg_sample) * 100\n",
    "    mean_roa = reg_sample.loc[mask, 'ROA'].mean() if n > 0 else np.nan\n",
    "    exposure_data.append({\n",
    "        'Exposure Level': label,\n",
    "        'N': n,\n",
    "        'Percentage': round(pct, 1),\n",
    "        'Mean ROA': round(mean_roa, 4) if not np.isnan(mean_roa) else np.nan\n",
    "    })\n",
    "\n",
    "exposure_df = pd.DataFrame(exposure_data)\n",
    "print(exposure_df.to_string(index=False))\n",
    "\n",
    "exposure_file = OUTPUT_DIR / '03_EXPOSURE_DISTRIBUTION.csv'\n",
    "exposure_df.to_csv(exposure_file, index=False)\n",
    "print(f\"\\n   Saved: {exposure_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year-by-Year Statistics\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"YEAR-BY-YEAR STATISTICS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "yearly_stats = reg_sample.groupby(analysis_data.loc[reg_sample.index, 'YEAR']).agg({\n",
    "    'ROA': ['count', 'mean', 'std'],\n",
    "    'AFFECTED_RATIO': 'mean',\n",
    "    'DISASTER': 'mean',\n",
    "    'TOTAL_ASSETS': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "yearly_stats.columns = ['N', 'Mean_ROA', 'Std_ROA', 'Mean_Affected_Ratio', \n",
    "                        'Disaster_Rate', 'Mean_Assets']\n",
    "print(yearly_stats.to_string())\n",
    "\n",
    "yearly_file = OUTPUT_DIR / '03_YEARLY_STATISTICS.csv'\n",
    "yearly_stats.to_csv(yearly_file)\n",
    "print(f\"\\n   Saved: {yearly_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DELIVERABLE 4: Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DELIVERABLE 4: CORRELATION MATRIX\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Variables for correlation matrix\n",
    "corr_vars = ['ROA', 'AFFECTED_RATIO', 'LOG_ASSETS', 'LEVERAGE', \n",
    "             'num_disasters', 'total_facilities', 'exposed_facilities']\n",
    "\n",
    "# Calculate Pearson correlation matrix\n",
    "corr_matrix = reg_sample[corr_vars].corr().round(4)\n",
    "\n",
    "print(\"\\nPEARSON CORRELATION MATRIX\")\n",
    "print(\"-\"*80)\n",
    "print(corr_matrix.to_string())\n",
    "\n",
    "# Save correlation matrix\n",
    "corr_file_csv = OUTPUT_DIR / '04_CORRELATION_MATRIX.csv'\n",
    "corr_matrix.to_csv(corr_file_csv)\n",
    "print(f\"\\n   Saved: {corr_file_csv}\")\n",
    "\n",
    "try:\n",
    "    corr_file_xlsx = OUTPUT_DIR / '04_CORRELATION_MATRIX.xlsx'\n",
    "    corr_matrix.to_excel(corr_file_xlsx, engine='openpyxl')\n",
    "    print(f\"   Saved: {corr_file_xlsx}\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key correlations with significance tests\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"KEY CORRELATIONS WITH SIGNIFICANCE TESTS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "key_pairs = [\n",
    "    ('ROA', 'AFFECTED_RATIO', 'Main relationship of interest'),\n",
    "    ('ROA', 'LOG_ASSETS', 'Size-profitability relationship'),\n",
    "    ('ROA', 'LEVERAGE', 'Leverage-profitability relationship'),\n",
    "    ('AFFECTED_RATIO', 'LOG_ASSETS', 'Size-exposure relationship'),\n",
    "    ('AFFECTED_RATIO', 'total_facilities', 'Diversification-exposure'),\n",
    "]\n",
    "\n",
    "corr_tests = []\n",
    "for var1, var2, description in key_pairs:\n",
    "    r, p = stats.pearsonr(reg_sample[var1].dropna(), \n",
    "                          reg_sample.loc[reg_sample[var1].notna(), var2].dropna())\n",
    "    sig = '***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.10 else ''\n",
    "    corr_tests.append({\n",
    "        'Variable 1': var1,\n",
    "        'Variable 2': var2,\n",
    "        'Correlation': round(r, 4),\n",
    "        'P-value': round(p, 4),\n",
    "        'Significance': sig,\n",
    "        'Description': description\n",
    "    })\n",
    "\n",
    "corr_tests_df = pd.DataFrame(corr_tests)\n",
    "print(corr_tests_df.to_string(index=False))\n",
    "print(\"\\nSignificance: *** p<0.01, ** p<0.05, * p<0.10\")\n",
    "\n",
    "corr_tests_file = OUTPUT_DIR / '04_KEY_CORRELATIONS.csv'\n",
    "corr_tests_df.to_csv(corr_tests_file, index=False)\n",
    "print(f\"\\n   Saved: {corr_tests_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DELIVERABLE 5: Regression Output Tables (All Coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"DELIVERABLE 5: REGRESSION OUTPUT TABLES\")\nprint(\"Using LAGGED Disaster Exposure (Hsu et al. 2018)\")\nprint(\"=\"*80)\n\n# Prepare regression data - MUST have non-missing LAGGED exposure\nreg_data = analysis_data[['ROA', 'AFFECTED_RATIO', 'AFFECTED_RATIO_lag1', 'DISASTER_lag1',\n                          'LOG_ASSETS', 'LEVERAGE', 'PERMNO', 'YEAR', 'INTENSITY_lag1']].copy()\n\n# Drop observations with missing lagged exposure (first year per company)\nreg_data = reg_data.dropna(subset=['ROA', 'AFFECTED_RATIO_lag1', 'LOG_ASSETS', 'LEVERAGE'])\n\nprint(f\"\\nRegression sample (with LAGGED exposure):\")\nprint(f\"   Observations: {len(reg_data):,}\")\nprint(f\"   Unique companies: {reg_data['PERMNO'].nunique():,}\")\nprint(f\"   Years: {reg_data['YEAR'].min()}-{reg_data['YEAR'].max()}\")\nprint(f\"\\n   Note: First year per company dropped due to lagging\")\nprint(f\"\\n   AFFECTED_RATIO_lag1 stats:\")\nprint(f\"      Mean: {reg_data['AFFECTED_RATIO_lag1'].mean():.4f}\")\nprint(f\"      Std:  {reg_data['AFFECTED_RATIO_lag1'].std():.4f}\")\nprint(f\"      Min:  {reg_data['AFFECTED_RATIO_lag1'].min():.4f}\")\nprint(f\"      Max:  {reg_data['AFFECTED_RATIO_lag1'].max():.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# MODEL 1: Simple OLS with LAGGED exposure\nprint(\"\\n\" + \"=\"*80)\nprint(\"MODEL 1: SIMPLE OLS (Hsu et al. 2018)\")\nprint(\"ROA_t ~ AFFECTED_RATIO_t-1\")\nprint(\"=\"*80)\n\nmodel1 = smf.ols('ROA ~ AFFECTED_RATIO_lag1', data=reg_data).fit()\nprint(model1.summary())\n\n# Extract coefficients for export\nmodel1_coef = pd.DataFrame({\n    'Variable': model1.params.index,\n    'Coefficient': model1.params.values.round(6),\n    'Std_Error': model1.bse.values.round(6),\n    't_statistic': model1.tvalues.values.round(4),\n    'P_value': model1.pvalues.values.round(6),\n    'CI_Lower_95': model1.conf_int()[0].values.round(6),\n    'CI_Upper_95': model1.conf_int()[1].values.round(6)\n})\n\nmodel1_file = OUTPUT_DIR / '05a_MODEL1_SIMPLE_OLS_LAGGED.csv'\nmodel1_coef.to_csv(model1_file, index=False)\nprint(f\"\\n   Saved: {model1_file}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# MODEL 2: With Controls - LAGGED exposure\nprint(\"\\n\" + \"=\"*80)\nprint(\"MODEL 2: WITH FIRM CONTROLS (Hsu et al. 2018)\")\nprint(\"ROA_t ~ AFFECTED_RATIO_t-1 + LOG_ASSETS_t + LEVERAGE_t\")\nprint(\"=\"*80)\n\nmodel2 = smf.ols('ROA ~ AFFECTED_RATIO_lag1 + LOG_ASSETS + LEVERAGE', data=reg_data).fit()\nprint(model2.summary())\n\nmodel2_coef = pd.DataFrame({\n    'Variable': model2.params.index,\n    'Coefficient': model2.params.values.round(6),\n    'Std_Error': model2.bse.values.round(6),\n    't_statistic': model2.tvalues.values.round(4),\n    'P_value': model2.pvalues.values.round(6),\n    'CI_Lower_95': model2.conf_int()[0].values.round(6),\n    'CI_Upper_95': model2.conf_int()[1].values.round(6)\n})\n\nmodel2_file = OUTPUT_DIR / '05b_MODEL2_WITH_CONTROLS_LAGGED.csv'\nmodel2_coef.to_csv(model2_file, index=False)\nprint(f\"\\n   Saved: {model2_file}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# MODEL 3: With Year Fixed Effects - LAGGED exposure (MAIN SPECIFICATION)\nprint(\"\\n\" + \"=\"*80)\nprint(\"MODEL 3: WITH YEAR FIXED EFFECTS (Hsu et al. 2018 - MAIN)\")\nprint(\"ROA_t ~ AFFECTED_RATIO_t-1 + LOG_ASSETS_t + LEVERAGE_t + C(YEAR)\")\nprint(\"=\"*80)\n\nmodel3 = smf.ols('ROA ~ AFFECTED_RATIO_lag1 + LOG_ASSETS + LEVERAGE + C(YEAR)', data=reg_data).fit()\nprint(model3.summary())\n\nmodel3_coef = pd.DataFrame({\n    'Variable': model3.params.index,\n    'Coefficient': model3.params.values.round(6),\n    'Std_Error': model3.bse.values.round(6),\n    't_statistic': model3.tvalues.values.round(4),\n    'P_value': model3.pvalues.values.round(6),\n    'CI_Lower_95': model3.conf_int()[0].values.round(6),\n    'CI_Upper_95': model3.conf_int()[1].values.round(6)\n})\n\nmodel3_file = OUTPUT_DIR / '05c_MODEL3_YEAR_FE_LAGGED.csv'\nmodel3_coef.to_csv(model3_file, index=False)\nprint(f\"\\n   Saved: {model3_file}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# SUMMARY TABLE: All Models Compared (LAGGED Exposure)\nprint(\"\\n\" + \"=\"*80)\nprint(\"REGRESSION RESULTS SUMMARY (Hsu et al. 2018 - LAGGED Exposure)\")\nprint(\"=\"*80)\n\nsummary_table = pd.DataFrame({\n    'Specification': ['Model 1: Simple OLS', 'Model 2: With Controls', 'Model 3: Year FE (Main)'],\n    'AFFECTED_RATIO_lag1_Coef': [model1.params['AFFECTED_RATIO_lag1'], \n                                  model2.params['AFFECTED_RATIO_lag1'],\n                                  model3.params['AFFECTED_RATIO_lag1']],\n    'AFFECTED_RATIO_lag1_SE': [model1.bse['AFFECTED_RATIO_lag1'],\n                                model2.bse['AFFECTED_RATIO_lag1'],\n                                model3.bse['AFFECTED_RATIO_lag1']],\n    'AFFECTED_RATIO_lag1_Pval': [model1.pvalues['AFFECTED_RATIO_lag1'],\n                                  model2.pvalues['AFFECTED_RATIO_lag1'],\n                                  model3.pvalues['AFFECTED_RATIO_lag1']],\n    'LOG_ASSETS_Coef': [np.nan, model2.params['LOG_ASSETS'], model3.params['LOG_ASSETS']],\n    'LEVERAGE_Coef': [np.nan, model2.params['LEVERAGE'], model3.params['LEVERAGE']],\n    'R_squared': [model1.rsquared, model2.rsquared, model3.rsquared],\n    'Adj_R_squared': [model1.rsquared_adj, model2.rsquared_adj, model3.rsquared_adj],\n    'F_statistic': [model1.fvalue, model2.fvalue, model3.fvalue],\n    'N': [int(model1.nobs), int(model2.nobs), int(model3.nobs)],\n    'Year_FE': ['No', 'No', 'Yes']\n}).round(6)\n\nprint(summary_table.to_string(index=False))\n\nsummary_file = OUTPUT_DIR / '05d_REGRESSION_SUMMARY_LAGGED.csv'\nsummary_table.to_csv(summary_file, index=False)\nprint(f\"\\n   Saved: {summary_file}\")\n\ntry:\n    summary_xlsx = OUTPUT_DIR / '05d_REGRESSION_SUMMARY_LAGGED.xlsx'\n    summary_table.to_excel(summary_xlsx, index=False, engine='openpyxl')\n    print(f\"   Saved: {summary_xlsx}\")\nexcept:\n    pass"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create publication-style regression table (LAGGED)\nprint(\"\\n\" + \"=\"*80)\nprint(\"PUBLICATION-STYLE REGRESSION TABLE (Hsu et al. 2018)\")\nprint(\"=\"*80)\n\ndef format_coef(coef, se, pval):\n    \"\"\"Format coefficient with significance stars\"\"\"\n    stars = '***' if pval < 0.01 else '**' if pval < 0.05 else '*' if pval < 0.10 else ''\n    return f\"{coef:.4f}{stars}\", f\"({se:.4f})\"\n\npub_table = []\n\n# AFFECTED_RATIO_lag1 row (KEY VARIABLE)\nrow = {'Variable': 'AFFECTED_RATIO (t-1)'}\nfor i, model in enumerate([model1, model2, model3], 1):\n    coef_str, se_str = format_coef(model.params['AFFECTED_RATIO_lag1'], \n                                   model.bse['AFFECTED_RATIO_lag1'],\n                                   model.pvalues['AFFECTED_RATIO_lag1'])\n    row[f'Model_{i}'] = coef_str\n    row[f'Model_{i}_SE'] = se_str\npub_table.append(row)\n\n# LOG_ASSETS row\nrow = {'Variable': 'LOG_ASSETS (t)'}\nrow['Model_1'] = ''\nrow['Model_1_SE'] = ''\nfor i, model in enumerate([model2, model3], 2):\n    coef_str, se_str = format_coef(model.params['LOG_ASSETS'],\n                                   model.bse['LOG_ASSETS'],\n                                   model.pvalues['LOG_ASSETS'])\n    row[f'Model_{i}'] = coef_str\n    row[f'Model_{i}_SE'] = se_str\npub_table.append(row)\n\n# LEVERAGE row\nrow = {'Variable': 'LEVERAGE (t)'}\nrow['Model_1'] = ''\nrow['Model_1_SE'] = ''\nfor i, model in enumerate([model2, model3], 2):\n    coef_str, se_str = format_coef(model.params['LEVERAGE'],\n                                   model.bse['LEVERAGE'],\n                                   model.pvalues['LEVERAGE'])\n    row[f'Model_{i}'] = coef_str\n    row[f'Model_{i}_SE'] = se_str\npub_table.append(row)\n\n# Intercept row\nrow = {'Variable': 'Intercept'}\nfor i, model in enumerate([model1, model2, model3], 1):\n    coef_str, se_str = format_coef(model.params['Intercept'],\n                                   model.bse['Intercept'],\n                                   model.pvalues['Intercept'])\n    row[f'Model_{i}'] = coef_str\n    row[f'Model_{i}_SE'] = se_str\npub_table.append(row)\n\n# Model statistics\npub_table.append({'Variable': 'Year Fixed Effects', 'Model_1': 'No', 'Model_1_SE': '',\n                  'Model_2': 'No', 'Model_2_SE': '', 'Model_3': 'Yes', 'Model_3_SE': ''})\npub_table.append({'Variable': 'R-squared', \n                  'Model_1': f\"{model1.rsquared:.4f}\", 'Model_1_SE': '',\n                  'Model_2': f\"{model2.rsquared:.4f}\", 'Model_2_SE': '',\n                  'Model_3': f\"{model3.rsquared:.4f}\", 'Model_3_SE': ''})\npub_table.append({'Variable': 'N', \n                  'Model_1': f\"{int(model1.nobs):,}\", 'Model_1_SE': '',\n                  'Model_2': f\"{int(model2.nobs):,}\", 'Model_2_SE': '',\n                  'Model_3': f\"{int(model3.nobs):,}\", 'Model_3_SE': ''})\n\npub_df = pd.DataFrame(pub_table)\nprint(pub_df.to_string(index=False))\nprint(\"\\nNote: *** p<0.01, ** p<0.05, * p<0.10. Standard errors in parentheses.\")\nprint(\"      Disaster exposure is LAGGED (t-1) per Hsu et al. (2018)\")\n\npub_file = OUTPUT_DIR / '05e_PUBLICATION_TABLE_LAGGED.csv'\npub_df.to_csv(pub_file, index=False)\nprint(f\"\\n   Saved: {pub_file}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: All Deliverables Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"GENERATION COMPLETE - ALL DELIVERABLES FOR PROFESSOR YANG\")\nprint(\"Following Hsu et al. (2018) Methodology with LAGGED Exposure\")\nprint(\"=\"*80)\n\nprint(f\"\\nOutput directory: {OUTPUT_DIR}\")\nprint(\"\\nFiles generated:\")\nprint(\"-\" * 80)\n\nfor file in sorted(OUTPUT_DIR.glob('*')):\n    if file.is_file():\n        size_kb = file.stat().st_size / 1024\n        print(f\"  {file.name:<50} ({size_kb:.1f} KB)\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"DELIVERABLES SUMMARY\")\nprint(\"=\"*80)\nprint(\"\"\"\n1. COMPLETE ANALYSIS DATASET\n   - 01_COMPLETE_ANALYSIS_DATASET.csv/xlsx\n   - 01_DATA_DICTIONARY.csv\n\n2. STATISTICAL MODEL SPECIFICATION\n   - 02_STATISTICAL_MODEL_SPECIFICATION.txt\n   - Following Hsu et al. (2018) LAGGED methodology\n\n3. DESCRIPTIVE STATISTICS\n   - 03_DESCRIPTIVE_STATISTICS.csv/xlsx\n   - 03_EXPOSURE_DISTRIBUTION.csv\n   - 03_YEARLY_STATISTICS.csv\n\n4. CORRELATION MATRIX\n   - 04_CORRELATION_MATRIX.csv/xlsx\n   - 04_KEY_CORRELATIONS.csv\n\n5. REGRESSION OUTPUT TABLES (LAGGED per Hsu et al. 2018)\n   - 05a_MODEL1_SIMPLE_OLS_LAGGED.csv\n   - 05b_MODEL2_WITH_CONTROLS_LAGGED.csv\n   - 05c_MODEL3_YEAR_FE_LAGGED.csv\n   - 05d_REGRESSION_SUMMARY_LAGGED.csv/xlsx\n   - 05e_PUBLICATION_TABLE_LAGGED.csv\n\"\"\")\n\nprint(\"=\"*80)\nprint(\"KEY FINDINGS (Hsu et al. 2018 Methodology - LAGGED Exposure)\")\nprint(\"=\"*80)\nprint(f\"\"\"\nMAIN RESULT: Effect of LAGGED disaster exposure on ROA\n\nModel 1 (Simple OLS):     beta = {model1.params['AFFECTED_RATIO_lag1']:.4f}, p = {model1.pvalues['AFFECTED_RATIO_lag1']:.3f}\nModel 2 (With Controls):  beta = {model2.params['AFFECTED_RATIO_lag1']:.4f}, p = {model2.pvalues['AFFECTED_RATIO_lag1']:.3f}\nModel 3 (Year FE - Main): beta = {model3.params['AFFECTED_RATIO_lag1']:.4f}, p = {model3.pvalues['AFFECTED_RATIO_lag1']:.3f}\n\nSample: {int(model1.nobs):,} firm-year observations (after lagging)\n        {reg_data['PERMNO'].nunique()} manufacturing companies\n        {reg_data['YEAR'].min()}-{reg_data['YEAR'].max()} period\n\nModel Specification (Hsu et al. 2018):\nROA_it = beta_0 + beta_1 * AFFECTED_RATIO_i,t-1 + beta_2 * LOG_ASSETS_it \n       + beta_3 * LEVERAGE_it + Year_FE + epsilon_it\n\nKey: Disaster exposure is LAGGED by one year (t-1)\n     Controls are contemporaneous (year t)\n\"\"\")\nprint(\"=\"*80)\nprint(\"All statistical outputs successfully generated!\")\nprint(\"=\"*80)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}